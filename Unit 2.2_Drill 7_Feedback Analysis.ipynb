{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style = 'font-family:Book Antiqua'><font size = 3>\n",
    "    <i>Unit 2.2 Project 7</i>\n",
    "    \n",
    "<font style = 'font-family:Book Antiqua'><font size = 7>\n",
    "    <b>Challenge: Feedback Analysis</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style = 'font-family:Book Antiqua'><font size = 5><b>Assignment:</b>\n",
    "    \n",
    "<font size = 4>Pick one of the company data files and build your own classifier. When you're satisfied with its performance (at this point just using the accuracy measure shown in the example), test it on one of the other datasets to see how well these kinds of classifiers translate from one context to another.\n",
    "\n",
    "Include your model and a brief writeup of your feature engineering and selection process to submit and review with your mentor.\n",
    "<hr width=50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style = 'font-family:Book Antiquea'><font size = 5><b>Challenge:</b>\n",
    "    \n",
    "<font size = 4> For this challenge, I have chosen to use the Amazon data set from <a href='https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences'>UCI learning dataset of sentiment labelled sentences</a>.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  score\n",
       "0  So there is no way for me to plug it in here i...      0\n",
       "1                        Good case, Excellent value.      1\n",
       "2                             Great for the jawbone.      1\n",
       "3  Tied to charger for conversations lasting more...      0\n",
       "4                                  The mic is great.      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grabbing and process the raw data.\n",
    "amazon = ('amazon_cells_labelled.txt')\n",
    "amazon = pd.read_csv(amazon, delimiter= '\\t', header=None)\n",
    "amazon.columns = ['sentence', 'score'] # 1 = positive 0 = negative\n",
    "\n",
    "amazon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style = 'font-family:Book Antiquea'><font size = 4>In the dataset, we can see that there are two columns, a sentence and a label. From the guided example in the previous section, we know that a sentence is not really a feature and is not super helpful. In this case, the two columns would be used to predict whether a review is positive or negative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style = 'font-family:Book Antiquea'><font size = 4><b>Learning the Data Set</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style = 'font-family:Book Antiquea'><font size = 4>Below I am analyzing the dataset to see what descriptive words or phrases I can use to determine if a review is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon['score'] = (amazon['score']==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for patterns in the dataset and standardizing the data to one format.\n",
    "amazon['sentence'] = amazon.sentence.str.replace(r'[^a-zA-Z\\d\\s:]', '')\n",
    "amazon['sentence'] = amazon['sentence'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split negative messages and combine into one list\n",
    "positive_words = amazon.sentence[amazon.score].str.cat(sep=' ').split()\n",
    "\n",
    "negative_words = amazon.sentence[amazon.score == False].str.cat(sep=' ').split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style = 'font-family:Book Antiqua'><font size = 4>Below is the count of unique positive and negative words that one can use to analyze if a review is good or bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique negative words: 1293\n"
     ]
    }
   ],
   "source": [
    "print ('Number of unique negative words:',len(np.unique(negative_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique postive words: 1137\n"
     ]
    }
   ],
   "source": [
    "print ('Number of unique postive words:',len(np.unique(positive_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style ='font-family:Book Antiqua'><font size =4>In the two code blocks below, I am creating two arrays. The first array contains all the postive keywords in the column <b><i>sentence</i></b>. The second array returns the unique values that are not in either array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive keywords array:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['the', 'and', 'i', ..., 'rotating', 'setting', 'commuter'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a data frame to house positive keywords.\n",
    "print('Positive keywords array:')\n",
    "keywords = pd.Series(positive_words).value_counts().keys().ravel()\n",
    "\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values array:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['100', '15', '18', '2000', '2005', '24', '2mp', '325', '350', '42',\n",
       "       '5020', '680', '7', '700w', '8530', ':', ':oh', 'ac', 'accessable',\n",
       "       'accessing', 'accompanied', 'according', 'activesync', 'adapters',\n",
       "       'address', 'adorable', 'against', 'alarm', 'allot', 'allow',\n",
       "       'allowing', 'alot', 'aluminum', 'amazed', 'amazing', 'ample',\n",
       "       'ant', 'antiglare', 'anywhere', 'apart', 'appears', 'applifies',\n",
       "       'appointments', 'armband', 'arrival', 'ask', 'aspect', 'attacked',\n",
       "       'attractive', 'authentic', 'autoanswer', 'available', 'awesome',\n",
       "       'awsome', 'basic', 'batteries', 'beat', 'beats', 'beautiful',\n",
       "       'behing', 'bitpim', 'blackberry', 'blacktop', 'blueant',\n",
       "       'bluetoothmotorola', 'bluetooths', 'boot', 'bose', 'boy',\n",
       "       'brilliant', 'browser', 'browsing', 'bt250v', 'bubbling', 'build',\n",
       "       'bulky', 'cables', 'called', 'canal', 'cancellation', 'cancelling',\n",
       "       'capability', 'capacity', 'carried', 'carries', 'carry', 'cases',\n",
       "       'cat', 'cds', 'cellphone', 'cellular', 'center', 'cents',\n",
       "       'certainly', 'channel', 'chargelife', 'charm', 'cheaper', 'cheapy',\n",
       "       'china', 'choices', 'christmas', 'classy', 'clearer', 'clever',\n",
       "       'clipping', 'clips', 'clock', 'colleague', 'colors', 'combination',\n",
       "       'comfort', 'comfortably', 'comfortible', 'comments',\n",
       "       'communication', 'commuter', 'competitors', 'complaints',\n",
       "       'compliments', 'compromise', 'concrete', 'conditions',\n",
       "       'confortable', 'connect', 'control', 'controls', 'convenient',\n",
       "       'copier', 'corded', 'cost', 'coupon', 'crisp', 'curve', 'cut',\n",
       "       'cute', 'cutouts', 'damage', 'deffinitely', 'definitely',\n",
       "       'definitly', 'delivery', 'described', 'destroying', 'detachable',\n",
       "       'detailed', 'development', 'devices', 'dialing', 'directed',\n",
       "       'directly', 'display', 'distracting', 'division', 'docking',\n",
       "       'doing', 'done', 'download', 'downloading', 'dozens', 'driving',\n",
       "       'droid', 'dualpurpose', 'durable', 'eargels', 'earphones',\n",
       "       'earset', 'edge', 'effective', 'effects', 'effort', 'electronics',\n",
       "       'elegant', 'embedded', 'encourage', 'engineered', 'enjoy', 'enter',\n",
       "       'entertainment', 'entire', 'equipment', 'era', 'ericson',\n",
       "       'everyday', 'exactly', 'exceeds', 'excelent', 'excels',\n",
       "       'exceptional', 'excited', 'exclaim', 'existing', 'expensive',\n",
       "       'extended', 'exterior', 'eye', 'fabulous', 'faceplates', 'fact',\n",
       "       'factor', 'family', 'fantastic', 'fast', 'faster', 'favorite',\n",
       "       'features', 'file', 'finds', 'fingers', 'finished', 'fire', 'five',\n",
       "       'fixes', 'flawless', 'flawlessly', 'flaws', 'flipphones', 'fm',\n",
       "       'fraction', 'free', 'freedom', 'friends', 'frog', 'fulfills',\n",
       "       'functional', 'functionality', 'functions', 'funny', 'gadget',\n",
       "       'gadgets', 'gave', 'geeky', 'generally', 'glad', 'glasses',\n",
       "       'glove', 'good4', 'good7', 'gosh', 'graphics', 'greatno', 'grey',\n",
       "       'grip', 'gx2', 'h500', 'hair', 'hand', 'handheld', 'handset',\n",
       "       'handsfree', 'handy', 'happier', 'hardly', 'haul', 'havent', 'he',\n",
       "       'headbands', 'help', 'hey', 'highest', 'hitch', 'holding', 'hook',\n",
       "       'hour', 'hs850', 'humming', 'hybrid', 'iam', 'ideal', 'ie', 'igo',\n",
       "       'inconspicuous', 'increase', 'incrediable', 'incredible',\n",
       "       'incredibly', 'infatuated', 'inside', 'installed', 'instead',\n",
       "       'integrated', 'intended', 'internetto', 'invented', 'investment',\n",
       "       'ipod', 'ipods', 'ir', 'iriver', 'jabra350', 'jawbone', 'joy',\n",
       "       'juicehighy', 'jx10', 'keeping', 'key', 'keyboard', 'kindle',\n",
       "       'knock', 'knows', 'krussel', 'landline', 'laptop', 'lately',\n",
       "       'leather', 'leopard', 'lightly', 'liked', 'linked', 'linking',\n",
       "       'listener', 'lit', 'living', 'loads', 'longwearing', 'loop',\n",
       "       'lots', 'louder', 'loudest', 'loudglad', 'love', 'loved', 'loves',\n",
       "       'machine', 'magical', 'maintains', 'managementoh', 'mark',\n",
       "       'market', 'mega', 'mess', 'messages', 'metro', 'mine', 'miniusb',\n",
       "       'mobile', 'modest', 'motor', 'neat', 'needshandsfree', 'nice',\n",
       "       'nicely', 'noise', 'normally', 'nothingi', 'nyc', 'o', 'occupied',\n",
       "       'oem', 'offers', 'official', 'oozes', 'open', 'optimal', 'options',\n",
       "       'order', 'ordering', 'orders', 'organizational', 'otherwise',\n",
       "       'our', 'outgoing', 'outperform', 'outside', 'overall', 'overly',\n",
       "       'overnight', 'overnite', 'owned', 'owneryou', 'owning', 'package',\n",
       "       'packaged', 'pad', 'pain', 'paired', 'palms',\n",
       "       'palmtopcameracellphone', 'pants', 'passed', 'patient', 'pc',\n",
       "       'pcs', 'pda', 'peachykeen', 'peeling', 'penny', 'perfect',\n",
       "       'perfectly', 'performing', 'periods', 'phonesmp3', 'phonethe',\n",
       "       'pics', 'pixel', 'players', 'plays', 'pleasantly', 'pleased',\n",
       "       'plenty', 'plugs', 'pockets', 'portable', 'portraits', 'posted',\n",
       "       'practical', 'premium', 'prettier', 'prevents', 'priced', 'print',\n",
       "       'program', 'prompt', 'promptly', 'pros:good', 'protected',\n",
       "       'protective', 'protects', 'provides', 'ps3', 'psyched',\n",
       "       'purchases', 'quick', 'quit', 'qwerty', 'r', 'range', 'rate',\n",
       "       'rating', 'read', 'realize', 'realworld', 'reasonable',\n",
       "       'reasonably', 'rebootsoverall', 'reccomendation', 'receptiona',\n",
       "       'receptionsound', 'recognition', 'recommended', 'regret',\n",
       "       'relative', 'removing', 'replaceeasy', 'requirements', 'research',\n",
       "       'rest', 'restored', 'rests', 'reversible', 'reviews', 'ride',\n",
       "       'ringer', 'roam', 'rocks', 'roles', 'rotating', 'run', 's', 's11',\n",
       "       's710a', 'sanyo', 'satisfied', 'satisifed', 'saved', 'schr450',\n",
       "       'scratch', 'seamlessly', 'searched', 'secure', 'securely', 'see',\n",
       "       'seemed', 'seems', 'seen', 'self', 'seller', 'sensitive',\n",
       "       'setting', 'setup', 'sex', 'shape', 'sharp', 'shield', 'shifting',\n",
       "       'shine', 'shiny', 'shipment', 'shipped', 'shots', 'shouldve',\n",
       "       'show', 'shows', 'sight', 'signals', 'significantly', 'signs',\n",
       "       'simpler', 'sister', 'situations:1', 'sketchy', 'skype', 'sleek',\n",
       "       'slide', 'slider', 'sliding', 'slim', 'slipping', 'smallest',\n",
       "       'smoother', 'smoothly', 'soft', 'sold', 'solid', 'someone',\n",
       "       'somewhat', 'sooner', 'sos', 'sounds', 'source', 'span', 'specs',\n",
       "       'spinn', 'state', 'station', 'stays', 'stereo', 'stream', 'strip',\n",
       "       'sturdiness', 'sturdy', 'styles', 'styling', 'stylish',\n",
       "       'submerged', 'superb', 'supertooth', 'suprised', 'surefire',\n",
       "       'surprised', 'survived', 'sweetest', 'swivel', 'synchronization',\n",
       "       'thanks', 'theyre', 'thru', 'thumbs', 'tight', 'timely', 'tiny',\n",
       "       'tips', 'toactivate', 'toast', 'toneoverall', 'tools', 'total',\n",
       "       'tracfonewebsite', 'transceiver', 'transfer', 'transformed',\n",
       "       'transmission', 'transmit', 'transmitters', 'travled',\n",
       "       'tremendous', 'trunk', 'trythe', 'tv', 'type', 'understanding',\n",
       "       'unlike', 'upandcoming', 'upbeat', 'usable', 'usage', 'useful',\n",
       "       'usefulness', 'usually', 'v325i', 'value', 'via', 'video',\n",
       "       'virgin', 'voltage', 'vx', 'walkman', 'wallet', 'waterproof',\n",
       "       'web', 'websites', 'weight', 'welldesigned', 'wellit', 'wellwell',\n",
       "       'whatever', 'whether', 'whoa', 'whole', 'whose', 'wild',\n",
       "       'windresistant', 'winner', 'wise', 'wonderfully', 'wood',\n",
       "       'wornout', 'worthwhile', 'wow', 'yearsgreat', 'yes', 'youd',\n",
       "       'youll', 'z500a'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Unique values array:')\n",
    "diff = np.setdiff1d(\n",
    "        ar1=pd.Series(positive_words).value_counts().keys().ravel(), \n",
    "                      ar2=pd.Series(negative_words).value_counts().keys().ravel()\n",
    "                     )\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating a new feature using keywords from above array.\n",
    "new = amazon\n",
    "keywords = diff\n",
    "\n",
    "for key in keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    new[str(key)] = new.sentence.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying an outcome for model below.\n",
    "data = new[keywords]\n",
    "target = new['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style = 'font-family:Book Antiqua'><font size = 4>Lastly, we run a test on the model to determine the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 302\n",
      "Accuracy: 69.8%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "bnb.fit(data, target)\n",
    "\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\\nAccuracy: {}%\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum(), round((1 - (target != y_pred).sum()/data.shape[0]) * 100, 2)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style = 'font-family:Book Antiquea'><font size = 5><b>Run the same model on another dataset (Yelp)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font style = 'font-family:Book Antiqua'><font size = 4>For the second part of the assignment, I will run the same test on another data set (YelP) to determine how well the classifers in the Amazon dataset translate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  score\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp = pd.read_csv('yelp_labelled.txt', delimiter= '\\t', header=None)\n",
    "yelp.columns = ['review', 'score']\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp['score'] = (yelp['score'] == 1)\n",
    "yelp['review'] = yelp.review.str.replace(r'[^a-zA-Z\\d\\s:]', '')\n",
    "yelp['review'] = yelp['review'].str.lower()\n",
    "\n",
    "# split negative messages and combine into one list\n",
    "apositive_words = yelp.review[yelp.score].str.cat(sep=' ').split()\n",
    "\n",
    "anegative_words = yelp.review[yelp.score == False].str.cat(sep=' ').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique negative words: 1397\n",
      "Number of unique positive words: 1246\n"
     ]
    }
   ],
   "source": [
    "print ('Number of unique negative words:',len(np.unique(anegative_words)))\n",
    "print ('Number of unique positive words:',len(np.unique(apositive_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2007', '23', '6', '7', '70', 'absolute', 'absolutley', 'accident',\n",
       "       'accommodations', 'accomodate', 'accordingly', 'across', 'added',\n",
       "       'affordable', 'afternoon', 'airport', 'almonds', 'amazingrge',\n",
       "       'ambience', 'ample', 'andddd', 'app', 'appetizers', 'approval',\n",
       "       'aria', 'array', 'assure', 'atmosphere1', 'auju', 'awesome',\n",
       "       'ayce', 'az', 'baba', 'bacon', 'baklava', 'bank', 'bargain',\n",
       "       'bartender', 'bartenders', 'baseball', 'bbq', 'bean', 'beateous',\n",
       "       'beautiful', 'beautifully', 'beauty', 'beers', 'bellies', 'belly',\n",
       "       'biscuit', 'bits', 'blanket', 'block', 'bloddy', 'blue', 'bone',\n",
       "       'booksomethats', 'bowl', 'boxes', 'boyfriend', 'boys', 'bread',\n",
       "       'breakfastlunch', 'breeze', 'brick', 'brings', 'bruschetta',\n",
       "       'buffets', 'buldogis', 'bunch', 'butter', 'caballeros', 'caesar',\n",
       "       'caf', 'cakeohhh', 'calligraphy', 'cannoli', 'cape', 'capers',\n",
       "       'caring', 'carpaccio', 'case', 'cavier', 'chai', 'charming',\n",
       "       'cheek', 'cheesecurds', 'chef', 'chefs', 'chickenwith', 'chinese',\n",
       "       'chipotle', 'choose', 'choux', 'chow', 'claimed', 'classic',\n",
       "       'classywarm', 'club', 'cocktail', 'cocktails', 'cod', 'colder',\n",
       "       'combos', 'comfortable', 'companions', 'compliments',\n",
       "       'conclusion:', 'condiment', 'containers', 'continue', 'cool',\n",
       "       'corn', 'cotta', 'couples', 'court', 'courteous', 'cover',\n",
       "       'covered', 'coziness', 'cramming', 'cranberrymmmm', 'craving',\n",
       "       'crawfish', 'creamy', 'crema', 'crepe', 'crisp', 'crispy',\n",
       "       'croutons', 'crowds', 'crpe', 'crystals', 'customize', 'cute',\n",
       "       'daily', 'dark', 'date', 'dates', 'daughter', 'dead', 'decide',\n",
       "       'decision', 'decor', 'decorated', 'def', 'definately', 'degree',\n",
       "       'delicate', 'delicioso', 'delicious', 'deliciously', 'delight',\n",
       "       'delightful', 'delights', 'delish', 'dessert:', 'devine', 'die',\n",
       "       'dinners', 'disappoint', 'discount', 'dispenser', 'diverse',\n",
       "       'donut', 'dos', 'dough', 'dreamed', 'drenched', 'driving', 'duck',\n",
       "       'dude', 'duo', 'dusted', 'dylan', 'eclectic', 'efficient',\n",
       "       'eggplant', 'elegantly', 'email', 'enjoyable', 'enjoyed',\n",
       "       'enthusiastic', 'etc', 'ethic', 'event', 'events', 'exactly',\n",
       "       'exceeding', 'excellent', 'exceptional', 'expanded',\n",
       "       'expectations', 'experienced', 'expertconnisseur', 'exquisite',\n",
       "       'extensive', 'extra', 'extraordinary', 'eyed', 'fabulous',\n",
       "       'falafels', 'fantastic', 'fav', 'favorite', 'feeling', 'feels',\n",
       "       'fianc', 'fillet', 'fine', 'finger', 'firehouse', 'flair',\n",
       "       'flavored', 'flavorful', 'flavors', 'flavourful', 'flirting',\n",
       "       'fluffy', 'fo', 'four', 'francisco', 'free', 'frenchman', 'fruit',\n",
       "       'fry', 'fs', 'fun', 'funny', 'further', 'fuzzy', 'ganoush', 'gc',\n",
       "       'gem', 'generous', 'genuinely', 'gets', 'giant', 'giving', 'glad',\n",
       "       'glance', 'gluten', 'goat', 'goldencrispy', 'gooodd', 'gourmet',\n",
       "       'gratuity', 'great', 'greek', 'greeted', 'grilled', 'gringos',\n",
       "       'group', 'groups', 'guest', 'guys', 'halibut', 'han', 'handed',\n",
       "       'handled', 'handling', 'handmade', 'handsdown', 'hankering',\n",
       "       'happier', 'happy', 'hardest', 'haunt', 'havent', 'hawaiian',\n",
       "       'healthy', 'held', 'hella', 'hereas', 'hes', 'highlight',\n",
       "       'highlighted', 'highlights', 'highquality', 'hip', 'hiro', 'hits',\n",
       "       'hole', 'holiday', 'homemade', 'hooked', 'hoping', 'hottest',\n",
       "       'hummus', 'hungry', 'iced', 'imaginative', 'impeccable',\n",
       "       'included', 'including', 'incredible', 'incredibly', 'inexpensive',\n",
       "       'informative', 'inhouse', 'insanely', 'interesting', 'interior',\n",
       "       'inviting', 'ironman', 'italian', 'item', 'itfriendly', 'itll',\n",
       "       'jalapeno', 'jamaican', 'japanese', 'jeff', 'jewel', 'join',\n",
       "       'joint', 'joy', 'juries', 'khao', 'kiddos', 'killer', 'ladies',\n",
       "       'larger', 'las', 'lastly', 'latte', 'lawyers', 'legit', 'lemon',\n",
       "       'less', 'letting', 'level', 'light', 'lighter', 'lighting',\n",
       "       'lightly', 'likes', 'lil', 'listed', 'living', 'located', 'lordy',\n",
       "       'lots', 'loved', 'lovely', 'loves', 'loving', 'lowkey', 'lox',\n",
       "       'macarons', 'madison', 'magic', 'maine', 'maintaining', 'mandalay',\n",
       "       'mango', 'maria', 'marrow', 'marys', 'massive', 'mayo', 'meatloaf',\n",
       "       'meats', 'mediterranean', 'meet', 'meeverything', 'mein', 'melt',\n",
       "       'memory', 'mention', 'menus', 'mesquite', 'metro', 'mexican',\n",
       "       'mgm', 'middle', 'military', 'miss', 'missed', 'mixed', 'mmmm',\n",
       "       'modern', 'moist', 'mojitos', 'moms', 'monster', 'months', 'mood',\n",
       "       'mouth', 'mouthful', 'mouths', 'moz', 'mozzarella', 'ms',\n",
       "       'multigrain', 'mushrooms', 'mussels', 'muststop', 'naan', 'nan',\n",
       "       'nargile', 'nay', 'nearly', 'nicest', 'nigiri', 'nobu', 'nonfancy',\n",
       "       'north', 'nut', 'nyc', 'occasional', 'omelets', 'omg', 'onion',\n",
       "       'opinion', 'opposed', 'options', 'original', 'otto', 'ourselves',\n",
       "       'outdoor', 'outrageously', 'outshining', 'outstanding', 'oven',\n",
       "       'overwhelm', 'ownerchef', 'pack', 'pancake', 'panna', 'paper',\n",
       "       'party', 'past', 'pastas', 'pastry', 'patio', 'pats', 'peach',\n",
       "       'peanut', 'pears', 'peas', 'pecan', 'penne', 'pepper', 'perfect',\n",
       "       'perfection', 'perfectly', 'performed', 'perpared', 'personable',\n",
       "       'personally', 'petty', 'phenomenal', 'philadelphia', 'piano',\n",
       "       'pictures', 'pine', 'pineapple', 'pink', 'pita', 'plastic',\n",
       "       'platter', 'playing', 'pleased', 'pleasure', 'plethora', 'plus',\n",
       "       'pneumatic', 'portion', 'positive', 'powdered', 'power', 'prefer',\n",
       "       'prepared', 'priced', 'pricey', 'prime', 'professional',\n",
       "       'profiterole', 'prompt', 'promptly', 'pros', 'proven', 'provided',\n",
       "       'provides', 'providing', 'public', 'pumpkin', 'puree', 'put',\n",
       "       'quaint', 'quantity', 'raspberry', 'ravoli', 'reasonable',\n",
       "       'reasonably', 'receives', 'recommendation', 'redeeming',\n",
       "       'reduction', 'refreshing', 'regular', 'regularly', 'relax',\n",
       "       'relaxed', 'relleno', 'reminded', 'reminds', 'requested',\n",
       "       'returned', 'rib', 'ribeye', 'rich', 'rick', 'rightthe', 'rings',\n",
       "       'roll', 'rotating', 'round', 'rowdy', 's', 'saffron', 'salads',\n",
       "       'sals', 'salty', 'sample', 'san', 'sandwiches', 'satifying',\n",
       "       'satisfied', 'satisfying', 'saving', 'scottsdale', 'screams',\n",
       "       'seal', 'seasonal', 'seasoned', 'seasoning', 'second', 'section',\n",
       "       'selections', 'sergeant', 'serivce', 'serve', 'service:',\n",
       "       'servicecheck', 'sexy', 'shawarrrrrrma', 'shirt', 'shopping',\n",
       "       'shops', 'simple', 'sitdown', 'skimp', 'slaw', 'slices', 'smooth',\n",
       "       'smoothies', 'soi', 'solid', 'son', 'songs', 'soooo', 'sooooo',\n",
       "       'soundtrack', 'soups', 'sour', 'southwest', 'space', 'specials',\n",
       "       'speedy', 'spice', 'spicier', 'sporting', 'spot', 'spring',\n",
       "       'steaks', 'steiners', 'steve', 'sticks', 'stop', 'stopped',\n",
       "       'strawberry', 'street', 'stuff', 'stuffed', 'succulent', 'sugar',\n",
       "       'suggestions', 'summarize', 'summer', 'sun', 'sunday',\n",
       "       'sunglasses', 'supposed', 'surprise', 't', 'takeout', 'tapas',\n",
       "       'tartar', 'tartare', 'tastings', 'tater', 'teamwork', 'tender',\n",
       "       'terrific', 'thanks', 'theyre', 'thick', 'thinly', 'thrilled',\n",
       "       'thus', 'tigerlilly', 'tiny', 'tiramisu', 'toast', 'together',\n",
       "       'togo', 'tongue', 'top', 'topic', 'topvery', 'toro', 'tots',\n",
       "       'touch', 'town', 'transcendant', 'treat', 'tribute', 'trimmed',\n",
       "       'trips', 'truffle', 'truly', 'tucson', 'tummy', 'tvs', 'typical',\n",
       "       'unbelievable', 'unbelievably', 'unique', 'unreal', 'until',\n",
       "       'updatewent', 'upway', 'usual', 'vanilla', 'veganveggie',\n",
       "       'veggitarian', 'velvet', 'venture', 'venturing', 'venue', 'via',\n",
       "       'vinaigrette', 'violinists', 'visit', 'visited', 'vodka', 'voodoo',\n",
       "       'wagyu', 'waitresses', 'walls', 'watch', 'ways', 'wed', 'week',\n",
       "       'weekly', 'welcome', 'whenever', 'white', 'wide', 'wines',\n",
       "       'winner', 'wish', 'wonderful', 'wontons', 'words', 'world', 'wow',\n",
       "       'wrapped', 'wrong', 'yellow', 'yellowtail', 'youd', 'youll',\n",
       "       'youre', 'yukon'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "akeywords = pd.Series(anegative_words).value_counts().keys().ravel()\n",
    "\n",
    "adiff = np.setdiff1d(\n",
    "        ar1=pd.Series(apositive_words).value_counts().keys().ravel(), \n",
    "                      ar2=pd.Series(anegative_words).value_counts().keys().ravel()\n",
    "                     )\n",
    "adiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = yelp\n",
    "akeywords = adiff\n",
    "\n",
    "for key in akeywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    new[str(key)] = new.review.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = new[akeywords]\n",
    "target = new['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 1000 points : 294\n",
      "Accuracy: 70.6%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "bnb.fit(data, target)\n",
    "\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\\nAccuracy: {}%\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum(), round((1 - (target != y_pred).sum()/data.shape[0]) * 100, 2)\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
